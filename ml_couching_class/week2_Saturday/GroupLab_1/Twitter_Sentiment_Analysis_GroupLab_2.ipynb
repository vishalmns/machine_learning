{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be done in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to perform sentimental analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will be using twitter dataset as training data and crawled realtime tweets for testing. \n",
    "\n",
    "The Ground truth is 1 for positive tweet and 0 for negative tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few examples of positive and negative tweets are:\n",
    "\n",
    "**Few Positive Tweets: **\n",
    "1.  @Msdebramaye I heard about that contest! Congrats girl!!\n",
    "2. UNC!!! NCAA Champs!! Franklin St.: I WAS THERE!! WILD AND CRAZY!!!!!! Nothing like it...EVER http://tinyurl.com/49955t3\n",
    "\n",
    "**Few Negative Tweets:**\n",
    "1. no more taking Irish car bombs with strange Australian women who can drink like rockstars...my head hurts.\n",
    "2. Just had some bloodwork done. My arm hurts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "https://www.kaggle.com/c/twitter-sentiment-analysis2/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: (2 marks)\n",
    "\n",
    "The first exercise is cleaning the tweets.\n",
    "Perform preprocessing as required.\n",
    "\n",
    "Complete the functon : preprocess_tweets \n",
    "\n",
    "Input or Arguement to the function : tweet as a string \n",
    "\n",
    "Return value: processed tweet as string \n",
    "\n",
    "Hint: Use regular expressions\n",
    "* convert the all the cases into lower case\n",
    "  + look at lower()\n",
    "* Replace any urls with the word \"URL\"\n",
    "  + Hint : \n",
    "      - re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',\"Tweet\") (re is python regular expression package)\n",
    "* convert the username to \"AT_USER\", consider any word that starts with @ as user name\n",
    "  + Hint : \n",
    "      - re.sub('@[^\\s]+','AT_USER',\"Tweet\")\n",
    "* Remove multiple whitespaces with a single white space\n",
    "  + Hint :\n",
    "      - re.sub('[\\s]+', ' ', tweet)\n",
    "* Replace hashtag words (#word) with just the words (word)\n",
    "  + Hint : \n",
    "      - re.sub(r'#([^\\s]+)', r'\\1', \"tweet\")\n",
    "      \n",
    "* TEST CASE :\n",
    "    + given the tweet \"@V_DEL_ROSSI: Me         #dragging myself to the gym https://t.co/cOjM0mBVeY\"\n",
    "    + output should be \"AT_USER me dragging myself to the gym URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:16:37.343616Z",
     "start_time": "2018-06-30T14:16:37.336703Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweet):\n",
    "    #Code here\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: (3 marks)\n",
    "\n",
    "Tokenize the processed tweets to make a tweet into a list of words and make sure that no punctuations are returned. so that it can be used in the next steps to represent the tweet as a feature vector. Remove the Stops words, if necessary\n",
    "\n",
    "Complete the functon : word_tokenizer \n",
    "\n",
    "Input or Arguement to the function : processed tweet\n",
    "\n",
    "Return value: list of words without any punctuations\n",
    "\n",
    "TEST CASE :\n",
    "\n",
    "Given an input :\n",
    "    \"Neither Man, nor machine can replace its creator. really?.\"\n",
    "    \n",
    "Result : \n",
    "    ['neither', 'man', 'nor', 'machine', 'replace', 'creator', 'hahaha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:00:25.764720Z",
     "start_time": "2018-06-29T15:00:25.752064Z"
    }
   },
   "outputs": [],
   "source": [
    "stopWords = pd.read_csv('stopwords.txt').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:10:31.107306Z",
     "start_time": "2018-06-29T15:10:31.097419Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_tokenizer(tweet):\n",
    "    \n",
    "    return tokenized_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: (5 marks)\n",
    "\n",
    "Using the list of words from the above the step, \n",
    "* represent the tweet as a feature vector using bag of words\n",
    "\n",
    "Hint : counts of postive/negative/neutral words as three features can also be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:15:36.672042Z",
     "start_time": "2018-06-29T15:15:36.666906Z"
    }
   },
   "outputs": [],
   "source": [
    "def getfeaturevector(tokenized_tweet):\n",
    "#Code here\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: (Marks : 5 ) \n",
    "\n",
    "\n",
    "Load the given training data and use the above functions you created to process, to tokenise and to get feature vector.\n",
    "\n",
    "Considering the feature vector as input to the classifier, Train a classifier to classify the sentiment of the tweet correctly.\n",
    "\n",
    "Divide the training data into two sets, to validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: (Marks : 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter crawling using tweepy\n",
    "\n",
    "Use tweepy to get the tweets on real time, which is used as test data for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter account\n",
    "\n",
    "Create a twitter account if you don't have one by going to the link given below:\n",
    "\n",
    "https://twitter.com/i/flow/signup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy: tweepy is the python client for the official Twitter API.\n",
    "Install it using following pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets need to be gathered so as to perform Sentiment analysis on those tweets. They can be fetched from Twitter using the Twitter API. \n",
    "\n",
    "In order to fetch tweets through Twitter API, one needs to register an App through their twitter account. Follow these steps for the same:\n",
    "<ul>\n",
    "<li>Open the link given below to create a App through the twitter account.\n",
    "    https://apps.twitter.com\n",
    "<li>click the button: ‘Create New App’\n",
    "<li>Fill the application details. You can leave the callback url field empty.\n",
    "<li>Once the app is created, you will be redirected to the app page.\n",
    "<li>Open the ‘Keys and Access Tokens’ tab.\n",
    "<li>Copy ‘Consumer Key’, ‘Consumer Secret’, ‘Access token’ and ‘Access Token Secret’.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:04.892431Z",
     "start_time": "2018-06-29T14:11:04.881562Z"
    }
   },
   "outputs": [],
   "source": [
    "#Replace with your ‘Consumer Key’, ‘Consumer Secret’, ‘Access token’ and ‘Access Token Secret’ below. \n",
    "\n",
    "consumer_key = 'XXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXX'\n",
    "access_secret = 'XXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to authenticate your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:07.156485Z",
     "start_time": "2018-06-29T14:11:06.815300Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy Cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code gives the search results from twitter for the search string passed to the keyword arguement \"q\" in the tweepy.Cursor. The number passed to the items method of tweepy.Cursor indicates that it gives 100 such tweets, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:18:19.093637Z",
     "start_time": "2018-06-29T14:18:07.691456Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tweepy.Cursor(api.search, q='searchme', lang = 'en', full_text=True).items(100):\n",
    "    print(i._json['text'])\n",
    "    #print(processTweet(i._json['text']), end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also apply the preprocessing steps and obtain the feature vectors for the crawled twitter data.\n",
    "Classify the crawled tweets by passing its feature vector to the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
