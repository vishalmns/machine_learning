{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be done in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, we will use the data set on fruits which we explored earlier and learn how a simple K nearest neighbour classification works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us consider a simple situation. Given some data about a fruit, we want to label it automatically.\n",
    "\n",
    "Fruits are characterized by \n",
    " * weight in grams as a float\n",
    " * colour as an integer\n",
    "     - 1 $\\rightarrow$ red\n",
    "     - 2 $\\rightarrow$ orange\n",
    "     - 3 $\\rightarrow$ yellow\n",
    "     - 4 $\\rightarrow$ green\n",
    "     - 5 $\\rightarrow$ blue\n",
    "     - 6 $\\rightarrow$ purple\n",
    " * label as a string\n",
    "     - \"A\" $\\rightarrow$ Apple\n",
    "     - \"B\" $\\rightarrow$ Banana\n",
    "     \n",
    "We are given some sample data such as (303, 3, \"A\") meaning the fruit with 303 gram weight, and yellow colour is an apple. A set of such *training samples* is given in “01-train.csv”. This has a small set of 17 **labeled** samples. \n",
    "\n",
    "We are given a set of **test** data where only weight and colour are given,  eg. (373,1). We should design a simple Nearest Neighbour classifier that will find the fruit label. i.e., \"A\" or \"B\", meaning Apple or Banana. \n",
    "\n",
    "We have 102 such testcases, split into 30 in one file and 72 in the other. We are also given additional files which have the correct labels for all these 102 test cases. We can compare our predictions, with these. If your predicted label is correct, you have done well!\n",
    "\n",
    "Here are the details of all the files:\n",
    "  * **01-train.csv** $\\Rightarrow$ The original input data. \n",
    "    - 18 lines\n",
    "    - the first line is a header\n",
    "    - each of the remaining 17 lines has three pieces of data:\n",
    "       * weight in grams :: float\n",
    "       * colour code :: 1, 2, 3, 4, 5 \n",
    "       * label :: \"A\", \"B\"\n",
    "  * **01-test1.csv** $\\Rightarrow$ The first test data set.\n",
    "    - 31 lines\n",
    "    - the first line is a header\n",
    "    - each of the remaining 30 lines has two pieces of data\n",
    "       * weight in grams :: float\n",
    "       * colour code :: 1, 2, 3, 4, 5\n",
    "  * **01-test1-labels.csv** $\\Rightarrow$ The labels for test data set above. That is, each line has just the correct label.\n",
    "  * **01-test2.csv** $\\Rightarrow$ The second test data set. Similar to the first data set, except that it has 73 lines.\n",
    "  * **01-test2-labels.csv** $\\Rightarrow$ The labels for test data set above. That is, each line has just the correct label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:19.501062Z",
     "start_time": "2018-05-31T13:00:19.497163Z"
    }
   },
   "outputs": [],
   "source": [
    "## Let us set up the file names\n",
    "FRUITS_TRAIN = \"../Datasets/AIML_DS_TRAIN_SAMPLE.csv\"\n",
    "FRUITS_TEST1 = \"../Datasets/AIML_DS_TEST1_SAMPLE.csv\"\n",
    "FRUITS_LABELS1 = \"../Datasets/AIML_DS_TEST1-LABELS_SAMPLE.csv\"\n",
    "FRUITS_TEST2 = \"../Datasets/AIML_DS_TEST2_SAMPLE.CSV\"\n",
    "FRUITS_LABELS2 = \"../Datasets/AIML_DS_TEST2-LABELS_SAMPLE.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:21.092038Z",
     "start_time": "2018-05-31T13:00:20.843075Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let us first read the data from the file and do a quick visualization\n",
    "import pandas as pd\n",
    "train = pd.read_csv(FRUITS_TRAIN)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:22.012172Z",
     "start_time": "2018-05-31T13:00:21.841236Z"
    }
   },
   "outputs": [],
   "source": [
    "apples = train[train.Label == \"A\"]\n",
    "bananas = train[train.Label == \"B\"]\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(apples.Weight, apples.Colour, \"ro\")\n",
    "plt.plot(bananas.Weight, bananas.Colour, \"y+\")\n",
    "plt.xlabel(\"Weight -- in grams\")\n",
    "plt.ylabel(\"Colour -- r-o-y-g-b-p\")\n",
    "plt.legend([\"Apples\", \"Bananas\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We  see that similar fruits come close in the feature (weight, color) space? Now let us plot one sample data given in black."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:23.798539Z",
     "start_time": "2018-05-31T13:00:23.639386Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(apples.Weight, apples.Colour, \"ro\")\n",
    "plt.plot(bananas.Weight, bananas.Colour, \"y+\")\n",
    "plt.xlabel(\"Weight -- in grams\")\n",
    "plt.ylabel(\"Colour -- r-o-y-g-b-p\")\n",
    "plt.legend([\"Apples\", \"Bananas\"])\n",
    "plt.plot([373], [1], \"ko\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the visualization alone, we can infer that the unknown fruit is likely to be an apple. \n",
    "\n",
    "The job now is to instead of eyeballing it one at a time like above, use a kNN classifier with, say, $k = 3$ and using the *Euclidean* distance, to determine the correct label for the data in the file \"01-test1.csv\" that has 30 data points. \n",
    "\n",
    "Let us first write a distance function to calculate the *Euclidean* distance between two fruits.\n",
    "\n",
    "$distance$ = $\\Sigma(a_i -b_i)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:25.017698Z",
     "start_time": "2018-05-31T13:00:25.013328Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def dist(a, b):\n",
    "    ''' a is the n-dimesnional co-ordinate of point 1\n",
    "        b is the n-dimensional co-ordinate of point 2'''\n",
    "    sqSum = 0\n",
    "    for i in range(len(a)):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return math.sqrt(sqSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us write code to find the $k$ nearest neighbours of a given fruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:26.281257Z",
     "start_time": "2018-05-31T13:00:26.278291Z"
    }
   },
   "outputs": [],
   "source": [
    "def kNN(k, train, given):\n",
    "    distances = []\n",
    "    for t in train.values:              \n",
    "        # loop over all training samples\n",
    "        distances.append((dist(t[:2], given), t[2])) \n",
    "        # compute and store distance of each training sample from the given sample\n",
    "    distances.sort()            \n",
    "    return distances[:k]    # return first k samples = nearest  k distances to the given sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:26.900834Z",
     "start_time": "2018-05-31T13:00:26.895790Z"
    }
   },
   "outputs": [],
   "source": [
    "print(kNN(3, train, (373, 1)))\n",
    "print(kNN(5, train, (373, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the 3 (and 5) nearest neighbours of the fruit with the characteristics (373, 1) are all Apples -- label 1; which is what we visually saw when we plotted the point as a black spot in the chart. Of course we need to write another function to get this attribute rather than read, so we have written a function for that. We have used collections.Counter, which we explored in the earlier experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:28.056817Z",
     "start_time": "2018-05-31T13:00:28.050966Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def kNNmax(k, train, given):\n",
    "    tally = collections.Counter()\n",
    "    for nn in kNN(k, train, given):\n",
    "        tally.update(nn[-1])\n",
    "    return tally.most_common(1)[0]\n",
    "print(kNNmax(5, train, (340, 1)))\n",
    "print(kNNmax(7, train, (340, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that of the five nearest neighbours to (340, 1) four are Apples and of the seven nearest, five are Apples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us load the test data and find the labels for all of them. Also let us count how many are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:29.750577Z",
     "start_time": "2018-05-31T13:00:29.686224Z"
    }
   },
   "outputs": [],
   "source": [
    "testData = pd.read_csv(FRUITS_TEST1).values\n",
    "testResults = pd.read_csv(FRUITS_LABELS1).values.flatten()\n",
    "results = []\n",
    "for i, t in enumerate(testData):\n",
    "    results.append(kNNmax(3, train, t)[0] == testResults[i])\n",
    "print(results.count(True), \"are correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** :: Find the accuracy of your prediction -- percentage of the samples that are correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:30.920878Z",
     "start_time": "2018-05-31T13:00:30.917051Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2** :: Predict the labels for the larger test file that has 72 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-31T13:00:32.201250Z",
     "start_time": "2018-05-31T13:00:32.197340Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with 17 samples we are predicting (rather accurately) the labels on a larger level -- 30 and 72!\n",
    "\n",
    "**Exercise 3** :: Find the accuracy of the prediction by comparing with \"01-test2-labels.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.381633Z",
     "start_time": "2018-05-24T09:08:24.315898Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4** :: Repeat the above experiment with $k = 5$ and $k = 7$. Explain which $k$ is better and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.452078Z",
     "start_time": "2018-05-24T09:08:24.384070Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5** :: Repeat the above experiment with $k = 17$. What do you think is happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.519143Z",
     "start_time": "2018-05-24T09:08:24.455490Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6** :: If the weights are in Kgs, that is divide all of the data in weights column by 1000, what is the accuracy for $k = 3$? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.583846Z",
     "start_time": "2018-05-24T09:08:24.522790Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** :: Modify the distance function to ignore the colour feature. Calculate the accuracy on the smaller test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.655826Z",
     "start_time": "2018-05-24T09:08:24.585834Z"
    }
   },
   "outputs": [],
   "source": [
    "def dist(a, b):\n",
    "    ## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8** :: If we used the square of the Euclidean distance, for the distance fuction does it affect the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.656767Z",
     "start_time": "2018-05-24T09:08:23.116Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Exercise 9** :: If we use the sum of the absolute differences, as the distance metric instead of the Euclidean, how does that affect the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-24T09:08:24.658142Z",
     "start_time": "2018-05-24T09:08:23.118Z"
    }
   },
   "outputs": [],
   "source": [
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "In the above experiment, we find that \n",
    " * a simple nearest neighbour method can successfully predict labels with a small number of labelled examples. \n",
    " * But we also see that the results can go really wrong \n",
    "    - if we make some wrong choices (like weight in Kg, or a very large K).\n",
    "\n",
    "This should remind you about the practical expertise and experimental skills that will become equally important as we move forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acknowledgment\n",
    "This experiment is based on the blog post http://www.jiaaro.com/KNN-for-humans. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
