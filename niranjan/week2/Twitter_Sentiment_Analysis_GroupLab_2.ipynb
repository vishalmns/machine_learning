{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be done in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to perform sentimental analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will be using twitter dataset as training data and crawled realtime tweets for testing. \n",
    "\n",
    "The Ground truth is 1 for positive tweet and 0 for negative tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few examples of positive and negative tweets are:\n",
    "\n",
    "**Few Positive Tweets: **\n",
    "1.  @Msdebramaye I heard about that contest! Congrats girl!!\n",
    "2. UNC!!! NCAA Champs!! Franklin St.: I WAS THERE!! WILD AND CRAZY!!!!!! Nothing like it...EVER http://tinyurl.com/49955t3\n",
    "\n",
    "**Few Negative Tweets:**\n",
    "1. no more taking Irish car bombs with strange Australian women who can drink like rockstars...my head hurts.\n",
    "2. Just had some bloodwork done. My arm hurts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "https://www.kaggle.com/c/twitter-sentiment-analysis2/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: (2 marks)\n",
    "\n",
    "The first exercise is cleaning the tweets.\n",
    "Perform preprocessing as required.\n",
    "\n",
    "Complete the functon : preprocess_tweets \n",
    "\n",
    "Input or Arguement to the function : tweet as a string \n",
    "\n",
    "Return value: processed tweet as string \n",
    "\n",
    "Hint: Use regular expressions\n",
    "* convert the all the cases into lower case\n",
    "  + look at lower()\n",
    "* Replace any urls with the word \"URL\"\n",
    "  + Hint : \n",
    "      - re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',\"Tweet\") (re is python regular expression package)\n",
    "* convert the username to \"AT_USER\", consider any word that starts with @ as user name\n",
    "  + Hint : \n",
    "      - re.sub('@[^\\s]+','AT_USER',\"Tweet\")\n",
    "* Remove multiple whitespaces with a single white space\n",
    "  + Hint :\n",
    "      - re.sub('[\\s]+', ' ', tweet)\n",
    "* Replace hashtag words (#word) with just the words (word)\n",
    "  + Hint : \n",
    "      - re.sub(r'#([^\\s]+)', r'\\1', \"tweet\")\n",
    "      \n",
    "* TEST CASE :\n",
    "    + given the tweet \"@V_DEL_ROSSI: Me         #dragging myself to the gym https://t.co/cOjM0mBVeY\"\n",
    "    + output should be \"AT_USER me dragging myself to the gym URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import feature_extraction, svm\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:16:37.343616Z",
     "start_time": "2018-06-30T14:16:37.336703Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_tweets(tweet):\n",
    "    #Code here\n",
    "    #print(\"Original: \" ,tweet)\n",
    "    #Convert to lower\n",
    "    tweet = tweet.lower()\n",
    "    #print(\"To lower: \", tweet)\n",
    "    \n",
    "    #Replace URL\n",
    "    tweet = re.sub('((www.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #print(\"Removing URL : \", tweet)\n",
    "    \n",
    "    #Replace @user\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #print(\"Removing @user : \", tweet)\n",
    "    \n",
    "    #Replace multiple whitespace\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #print(\"Removing multiple space : \", tweet)\n",
    "    \n",
    "    #Replace hashtag\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    #print(\"Removing # : \", tweet)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "# Test it out\n",
    "tweet = preprocess_tweets(\"@V_DEL_ROSSI: Me #dragging myself to     the gym   https://t.co/cOjM0mBVeY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: (3 marks)\n",
    "\n",
    "Tokenize the processed tweets to make a tweet into a list of words and make sure that no punctuations are returned. so that it can be used in the next steps to represent the tweet as a feature vector. Remove the Stops words, if necessary\n",
    "\n",
    "Complete the functon : word_tokenizer \n",
    "\n",
    "Input or Arguement to the function : processed tweet\n",
    "\n",
    "Return value: list of words without any punctuations\n",
    "\n",
    "TEST CASE :\n",
    "\n",
    "Given an input :\n",
    "    \"Neither Man, nor machine can replace its creator. really?.\"\n",
    "    \n",
    "Result : \n",
    "    ['neither', 'man', 'nor', 'machine', 'replace', 'creator', 'hahaha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:00:25.764720Z",
     "start_time": "2018-06-29T15:00:25.752064Z"
    }
   },
   "outputs": [],
   "source": [
    "stopWords = pd.read_csv('stopwords.txt')[\"a\"].values.tolist()\n",
    "stopWords = set(stopWords)\n",
    "\n",
    "posWords = pd.read_csv('positive-words.txt')[\"a+\"].values.tolist()\n",
    "posWords = set(posWords)\n",
    "\n",
    "negWords = pd.read_csv('negative-words.txt')[\"S2-faced\"].values.tolist()\n",
    "negWords = set(negWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:10:31.107306Z",
     "start_time": "2018-06-29T15:10:31.097419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neither', 'machine', 'creator', 'replace', 'hahaha', 'nor']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def word_tokenizer(tweet):\n",
    "    \n",
    "    tweet_words = re.split(r\"[\\W\\s_]+\", tweet)\n",
    "    tweet_words = list(filter(None, tweet_words))\n",
    "    \n",
    "    tokenized_tweet = [word for word in tweet_words if word not in stopWords]\n",
    "    return list(set(tokenized_tweet))\n",
    "\n",
    "tweet = \"Neither Man, nor machine can replace its creator. really?. hahaha hahaha\"\n",
    "tweet = preprocess_tweets(tweet)\n",
    "word_tokenizer(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: (5 marks)\n",
    "\n",
    "Using the list of words from the above the step, \n",
    "* represent the tweet as a feature vector using bag of words\n",
    "\n",
    "Hint : counts of postive/negative/neutral words as three features can also be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:15:36.672042Z",
     "start_time": "2018-06-29T15:15:36.666906Z"
    }
   },
   "outputs": [],
   "source": [
    "def getfeaturevector(tokenized_tweet):\n",
    "#Code here\n",
    "    pos, neg, neu = 0,0,0\n",
    "    for x in tokenized_tweet:\n",
    "        if x in posWords:\n",
    "            pos += 1\n",
    "        elif x in negWords:\n",
    "            neg += 1\n",
    "        else:\n",
    "            neu += 1 \n",
    "    return [pos, neg, neu]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: (Marks : 5 ) \n",
    "\n",
    "\n",
    "Load the given training data and use the above functions you created to process, to tokenise and to get feature vector.\n",
    "\n",
    "Considering the feature vector as input to the classifier, Train a classifier to classify the sentiment of the tweet correctly.\n",
    "\n",
    "Divide the training data into two sets, to validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                      SentimentText\n",
       "ItemID                                                              \n",
       "1               0                       is so sad for my APL frie...\n",
       "2               0                     I missed the New Moon trail...\n",
       "3               1                            omg its already 7:30 :O\n",
       "4               0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
       "5               0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read only 10k rows\n",
    "train = pd.read_csv(\"twitter_train.csv\", encoding = \"ISO-8859-1\", index_col=[\"ItemID\"], nrows=10000)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sad': 0, 'a': 1, '2': 2, 've': 3, 'im': 4, 'tonight': 5, 'tomorrow': 6, 'miss': 7, 'USER': 8, 'AT': 9, 'thanks': 10, 'day': 11, 'feel': 12, 'lt': 13, 'URL': 14, 'twitter': 15, 'gonna': 16, 'happy': 17, 'awesome': 18, 're': 19, '3': 20, 'please': 21, 'wish': 22, 'life': 23, 'sleep': 24, 'didn': 25, 'hate': 26, 'guys': 27, 'morning': 28, 'days': 29, 'week': 30, 'cant': 31, 'dont': 32, 'amp': 33, 'time': 34, 'fun': 35, 'love': 36, 'night': 37, 'lol': 38, 'home': 39, 'wanna': 40, '1': 41, '4': 42, 'bed': 43, 'gt': 44, 'hope': 45, 'll': 46, 'am': 47, 'quot': 48, 'oh': 49, 'getting': 50, 'people': 51, 'bad': 52, 'don': 53, 'haha': 54, 'school': 55, 'song': 56, 'follow': 57, 'followfriday': 58, 'myweakness': 59, 'musicmonday': 60, 'iremember': 61} 62\n"
     ]
    }
   ],
   "source": [
    "# Build a vocabulary\n",
    "\n",
    "# Get a hashmap or word and its respective count across all tweets\n",
    "word_counts = {}\n",
    "for index, row in train.iterrows():\n",
    "    tweet = row[1]\n",
    "    tweet_words = word_tokenizer(preprocess_tweets(tweet))\n",
    "    for word in tweet_words:\n",
    "        word_counts[word] = word_counts.get(word, 0) + 1\n",
    "\n",
    "# Word should be present in atleast 50 tweets and not in more than 5000 tweets\n",
    "vocabulary_list = []\n",
    "for word, count in word_counts.items():\n",
    "    if 100 < count < 5000:\n",
    "        vocabulary_list.append(word)\n",
    "\n",
    "# assign number to each word\n",
    "vocabulary = {word:i for i, word in enumerate(vocabulary_list)}\n",
    "print(vocabulary, len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(words, vocabulary):\n",
    "    vector = [0 for _ in range(len(vocabulary))]\n",
    "    for w in words:\n",
    "        if w in vocabulary:\n",
    "            vector[vocabulary[w]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Count_vector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                      SentimentText  \\\n",
       "ItemID                                                                 \n",
       "1               0                       is so sad for my APL frie...   \n",
       "2               0                     I missed the New Moon trail...   \n",
       "3               1                            omg its already 7:30 :O   \n",
       "4               0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "5               0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                             Count_vector  \n",
       "ItemID                                                     \n",
       "1       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "5       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cout vectors for each tweet\n",
    "train[\"Count_vector\"] = train[\"SentimentText\"].apply(lambda x: onehot(word_tokenizer(preprocess_tweets(x)), vocabulary))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Count_vector</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                      SentimentText  \\\n",
       "ItemID                                                                 \n",
       "1               0                       is so sad for my APL frie...   \n",
       "2               0                     I missed the New Moon trail...   \n",
       "3               1                            omg its already 7:30 :O   \n",
       "4               0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "5               0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                             Count_vector     Feature  \n",
       "ItemID                                                                 \n",
       "1       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 1, 2]  \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 1, 2]  \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 0, 3]  \n",
       "4       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 1, 12]  \n",
       "5       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 1, 2]  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get pos, neg, neutral counts\n",
    "train[\"Feature\"] = train[\"SentimentText\"].apply(lambda x: getfeaturevector(word_tokenizer(preprocess_tweets(x))))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Count_vector</th>\n",
       "      <th>Feature</th>\n",
       "      <th>sad</th>\n",
       "      <th>a</th>\n",
       "      <th>2</th>\n",
       "      <th>ve</th>\n",
       "      <th>im</th>\n",
       "      <th>tonight</th>\n",
       "      <th>...</th>\n",
       "      <th>school</th>\n",
       "      <th>song</th>\n",
       "      <th>follow</th>\n",
       "      <th>followfriday</th>\n",
       "      <th>myweakness</th>\n",
       "      <th>musicmonday</th>\n",
       "      <th>iremember</th>\n",
       "      <th>Neg</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Neu</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 0, 3]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "      <td>[0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 12]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Sentiment                                      SentimentText  \\\n",
       "ItemID                                                                 \n",
       "1               0                       is so sad for my APL frie...   \n",
       "2               0                     I missed the New Moon trail...   \n",
       "3               1                            omg its already 7:30 :O   \n",
       "4               0            .. Omgaga. Im sooo  im gunna CRy. I'...   \n",
       "5               0           i think mi bf is cheating on me!!!   ...   \n",
       "\n",
       "                                             Count_vector     Feature  sad  a  \\\n",
       "ItemID                                                                          \n",
       "1       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 1, 2]    1  0   \n",
       "2       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 1, 2]    0  0   \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 0, 3]    0  0   \n",
       "4       [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  [0, 1, 12]    0  1   \n",
       "5       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   [0, 1, 2]    0  0   \n",
       "\n",
       "        2  ve  im  tonight ...   school  song  follow  followfriday  \\\n",
       "ItemID                     ...                                        \n",
       "1       0   0   0        0 ...        0     0       0             0   \n",
       "2       0   0   0        0 ...        0     0       0             0   \n",
       "3       0   0   0        0 ...        0     0       0             0   \n",
       "4       1   1   1        0 ...        0     0       0             0   \n",
       "5       0   0   0        0 ...        0     0       0             0   \n",
       "\n",
       "        myweakness  musicmonday  iremember  Neg  Pos  Neu  \n",
       "ItemID                                                     \n",
       "1                0            0          0    0    1    2  \n",
       "2                0            0          0    0    1    2  \n",
       "3                0            0          0    0    0    3  \n",
       "4                0            0          0    0    1   12  \n",
       "5                0            0          0    0    1    2  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split up the count vectors and features into separate columns\n",
    "train[vocabulary_list] = pd.DataFrame(train[\"Count_vector\"].values.tolist(), index= train.index)\n",
    "train[[\"Neg\", \"Pos\", \"Neu\"]] = pd.DataFrame(train[\"Feature\"].values.tolist(), index= train.index)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sentiment', 'sad', 'a', '2', 've', 'im', 'tonight', 'tomorrow',\n",
       "       'miss', 'USER', 'AT', 'thanks', 'day', 'feel', 'lt', 'URL',\n",
       "       'twitter', 'gonna', 'happy', 'awesome', 're', '3', 'please',\n",
       "       'wish', 'life', 'sleep', 'didn', 'hate', 'guys', 'morning', 'days',\n",
       "       'week', 'cant', 'dont', 'amp', 'time', 'fun', 'love', 'night',\n",
       "       'lol', 'home', 'wanna', '1', '4', 'bed', 'gt', 'hope', 'll', 'am',\n",
       "       'quot', 'oh', 'getting', 'people', 'bad', 'don', 'haha', 'school',\n",
       "       'song', 'follow', 'followfriday', 'myweakness', 'musicmonday',\n",
       "       'iremember', 'Neg', 'Pos', 'Neu'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the list columns\n",
    "train.drop([\"SentimentText\", \"Count_vector\", \"Feature\"], inplace=True, axis=1)\n",
    "train.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80:20 Split\n",
    "X, Y = train.iloc[:, 1:], train.iloc[:,0]\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72175\n",
      "0.743\n"
     ]
    }
   ],
   "source": [
    "# Try out different classifiers\n",
    "classifier = svm.SVC(tol=0.3)\n",
    "#classifier = SGDClassifier(loss=\"log\", tol=10, max_iter= 10000, penalty=None)\n",
    "#classifier = RandomForestClassifier(max_features=6)\n",
    "\n",
    "classifier.fit(train_x, train_y)\n",
    "print(classifier.score(train_x, train_y))\n",
    "print(classifier.score(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: (Marks : 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter crawling using tweepy\n",
    "\n",
    "Use tweepy to get the tweets on real time, which is used as test data for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter account\n",
    "\n",
    "Create a twitter account if you don't have one by going to the link given below:\n",
    "\n",
    "https://twitter.com/i/flow/signup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy: tweepy is the python client for the official Twitter API.\n",
    "Install it using following pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets need to be gathered so as to perform Sentiment analysis on those tweets. They can be fetched from Twitter using the Twitter API. \n",
    "\n",
    "In order to fetch tweets through Twitter API, one needs to register an App through their twitter account. Follow these steps for the same:\n",
    "<ul>\n",
    "<li>Open the link given below to create a App through the twitter account.\n",
    "    https://apps.twitter.com\n",
    "<li>click the button: ‘Create New App’\n",
    "<li>Fill the application details. You can leave the callback url field empty.\n",
    "<li>Once the app is created, you will be redirected to the app page.\n",
    "<li>Open the ‘Keys and Access Tokens’ tab.\n",
    "<li>Copy ‘Consumer Key’, ‘Consumer Secret’, ‘Access token’ and ‘Access Token Secret’.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:04.892431Z",
     "start_time": "2018-06-29T14:11:04.881562Z"
    }
   },
   "outputs": [],
   "source": [
    "#Replace with your ‘Consumer Key’, ‘Consumer Secret’, ‘Access token’ and ‘Access Token Secret’ below. \n",
    "\n",
    "consumer_key = 'XXXXXXXXX'\n",
    "consumer_secret = 'XXXXXXXXXX'\n",
    "access_token = 'XXXXXXXXXXXXXX'\n",
    "access_secret = 'XXXXXXXXXXXXX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to authenticate your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:07.156485Z",
     "start_time": "2018-06-29T14:11:06.815300Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy Cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code gives the search results from twitter for the search string passed to the keyword arguement \"q\" in the tweepy.Cursor. The number passed to the items method of tweepy.Cursor indicates that it gives 100 such tweets, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:18:19.093637Z",
     "start_time": "2018-06-29T14:18:07.691456Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tweepy.Cursor(api.search, q='searchme', lang = 'en', full_text=True).items(100):\n",
    "    print(i._json['text'])\n",
    "    #print(processTweet(i._json['text']), end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also apply the preprocessing steps and obtain the feature vectors for the crawled twitter data.\n",
    "Classify the crawled tweets by passing its feature vector to the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
